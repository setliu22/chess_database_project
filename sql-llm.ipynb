{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy --quiet\n",
    "%pip install tenacity --quiet\n",
    "%pip install tiktoken --quiet\n",
    "%pip install termcolor --quiet\n",
    "%pip install openai --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "import os\n",
    "\n",
    "# Try to get the GITHUB_TOKEN from the system environment variables\n",
    "github_token = os.environ[\"GITHUB_KEY\"]\n",
    "if not github_token:\n",
    "    raise ValueError(\"GITHUB_TOKEN is not set in your system environment variables\")\n",
    "\n",
    "# Set the required OpenAI environment variables using the retrieved token\n",
    "os.environ[\"OPENAI_API_KEY\"] = github_token\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://models.inference.ai.azure.com/\"\n",
    "\n",
    "print(\"Environment variables have been set successfully.\")\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/arevel/chess-games\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "dataset = 'arevel/chess-games'  # Example: 'zillow/zecon'\n",
    "\n",
    "api.dataset_download_files(dataset, path='.', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6256184"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('chess_games.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "df = pd.read_csv('chess_games.csv')\n",
    "\n",
    "df.to_sql('Games', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_v5ezBetGA8PB1P8lfczBUbT1', function=Function(arguments='{\"query\":\"SELECT Opening, COUNT(Result) AS WhiteWins FROM Games WHERE Result = \\'1-0\\' GROUP BY Opening ORDER BY WhiteWins DESC LIMIT 10;\"}', name='ask_database'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "# Step #1: Prompt with content that may result in function call. In this case the model can identify the information requested by the user is potentially available in the database schema passed to the model in Tools description. \n",
    "messages = [{\n",
    "    \"role\":\"user\", \n",
    "    \"content\": \"What types of games have the most white wins?\"\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini', \n",
    "    messages=messages, \n",
    "    tools= tools, \n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "# Append the message to messages list\n",
    "response_message = response.choices[0].message \n",
    "messages.append(response_message)\n",
    "\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following types of games have recorded the most white wins based on various openings:\n",
      "\n",
      "1. **Scandinavian Defense: Mieses-Kotroc Variation** - 61,959 wins\n",
      "2. **Van't Kruijs Opening** - 58,014 wins\n",
      "3. **Modern Defense** - 51,785 wins\n",
      "4. **Horwitz Defense** - 50,010 wins\n",
      "5. **French Defense: Knight Variation** - 39,100 wins\n",
      "6. **Owen Defense** - 38,087 wins\n",
      "7. **Caro-Kann Defense** - 37,071 wins\n",
      "8. **Scandinavian Defense** - 36,161 wins\n",
      "9. **Sicilian Defense** - 35,958 wins\n",
      "10. **Philidor Defense #3** - 35,697 wins\n",
      "\n",
      "These openings have notably higher numbers of wins for White in games of chess.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "    tool_call_id = tool_calls[0].id\n",
    "    tool_function_name = tool_calls[0].function.name\n",
    "    tool_query_string = eval(tool_calls[0].function.arguments)['query']\n",
    "    \n",
    "    # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "    if tool_function_name == 'ask_database':\n",
    "        results = ask_database(conn, tool_query_string)\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\":\"tool\", \n",
    "            \"tool_call_id\":tool_call_id, \n",
    "            \"name\": tool_function_name, \n",
    "            \"content\":results\n",
    "        })\n",
    "        \n",
    "        # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "        # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "        model_response_with_function_call = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(model_response_with_function_call.choices[0].message.content)\n",
    "    else: \n",
    "        print(f\"Error: function {tool_function_name} does not exist\")\n",
    "else: \n",
    "    # Model did not identify a function to call, result can be returned to the user \n",
    "    print(response_message.content) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
